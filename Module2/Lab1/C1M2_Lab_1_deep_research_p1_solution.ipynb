{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fe220a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Agent, Task, Crew\n",
    "from crewai_tools import EXASearchTool, ScrapeWebsiteTool\n",
    "import os\n",
    "os.environ[\"CREWAI_TESTING\"] = \"true\"\n",
    "from utils import get_openai_api_key, get_exa_api_key\n",
    "from IPython.display import Markdown\n",
    "import yaml\n",
    "\n",
    "# set the OpenAI model (gpt-4o-mini)\n",
    "os.environ[\"MODEL\"] = \"gpt-4o-mini\"\n",
    "# set up the OpenAI API key \n",
    "os.environ[\"OPENAI_API_KEY\"] = get_openai_api_key()\n",
    "# set the EXA API key\n",
    "os.environ[\"EXA_API_KEY\"] = get_exa_api_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704540c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the tool instances\n",
    "exa_search_tool = EXASearchTool(base_url=os.getenv(\"EXA_BASE_URL\")) \n",
    "scrape_website_tool = ScrapeWebsiteTool()\n",
    "\n",
    "# load the configuration file for the agents\n",
    "with open('config/agents.yaml', 'r') as file:\n",
    "        agent_config = yaml.safe_load(file)\n",
    "\n",
    "# create the agents using the configuration\n",
    "research_planner = Agent(\n",
    "        config=agent_config['research_planner'],\n",
    "        verbose=True,\n",
    "        max_rpm=150,\n",
    "        max_iter=15\n",
    "        )\n",
    "internet_researcher = Agent(\n",
    "        config=agent_config['internet_researcher'],\n",
    "        tools=[exa_search_tool, scrape_website_tool],\n",
    "        verbose=True,\n",
    "        max_rpm=150,\n",
    "        max_iter=15\n",
    "        )\n",
    "fact_checker = Agent(\n",
    "        config=agent_config['fact_checker'],\n",
    "        tools=[exa_search_tool, scrape_website_tool],\n",
    "        verbose=True,\n",
    "        max_rpm=150,\n",
    "        max_iter=15\n",
    "        )\n",
    "report_writer = Agent(\n",
    "        config=agent_config['report_writer'],\n",
    "        verbose=True,\n",
    "        max_rpm=150,\n",
    "        max_iter=15\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239299d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# write the custom guardrail function\n",
    "def write_report_guardrail(output):\n",
    "    # get the raw output from the TaskOutput object\n",
    "    try:\n",
    "        output = output if type(output)==str else output.raw \n",
    "    except Exception as e:\n",
    "        return (False, (\"Error retrieving the `raw` argument: \"\n",
    "                        f\"\\n{str(e)}\\n\"\n",
    "                        )\n",
    "                )\n",
    "    \n",
    "    # convert the output to lowercase\n",
    "    output_lower = output.lower()\n",
    "\n",
    "    # check that the summary section exists\n",
    "    if not re.search(r'#+.*summary', output_lower):\n",
    "        return (False, \n",
    "                \"The report must include a Summary section with a header like '## Summary'\"\n",
    "                )\n",
    "\n",
    "    # check that the insights or recommendations sections exist\n",
    "    if not re.search(r'#+.*insights|#+.*recommendations', output_lower):\n",
    "        return (False, \n",
    "                \"The report must include an Insights section with a header like '## Insights'\"\n",
    "                )\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    # check that the citations (or references) section exists\n",
    "    if not re.search(r'#+.*citations|#+.*references', output_lower):\n",
    "        return (False,\n",
    "                \"The report must include a Citations (or References) section with a header like '## Citations'\"\n",
    "                )\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "    return (True, output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b08b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_report_pass = \"\"\"\n",
    "# Report title\n",
    "\n",
    "## Executive Summary\n",
    "This is a summary.\n",
    "\n",
    "## Insights\n",
    "These are the insights.\n",
    "\n",
    "## Citations\n",
    "1. Citation 1\n",
    "2. Citation 2\n",
    "\"\"\"\n",
    "\n",
    "write_report_guardrail(test_report_pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db4a9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_report_fail = \"\"\"\n",
    "# Report title\n",
    "\n",
    "## Executive Summary\n",
    "This is a summary.\n",
    "\"\"\"\n",
    "\n",
    "write_report_guardrail(test_report_fail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5e46c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the configuration file for the tasks\n",
    "with open('config/tasks.yaml', 'r') as file:\n",
    "    task_config = yaml.safe_load(file)\n",
    "\n",
    "### START CODE HERE ###\n",
    "\n",
    "# create the tasks using the configuration\n",
    "create_research_plan = Task(\n",
    "    config=task_config['create_research_plan'],\n",
    "    agent=research_planner\n",
    ")\n",
    "\n",
    "gather_research_data = Task(\n",
    "    config=task_config['gather_research_data'],\n",
    "    agent=internet_researcher,\n",
    ")\n",
    "\n",
    "verify_information_quality = Task(\n",
    "    config=task_config['verify_information_quality'],\n",
    "    agent=fact_checker,\n",
    ")\n",
    "\n",
    "write_final_report = Task(\n",
    "    config=task_config['write_final_report'],\n",
    "    agent=report_writer,\n",
    "    guardrails=[write_report_guardrail],\n",
    ")\n",
    "\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f065a43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_file_hook(result):\n",
    "    \"\"\"\n",
    "    Save the final research report to a local markdown file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get the final report content from the last task output\n",
    "        if hasattr(result, 'tasks_output') and result.tasks_output:\n",
    "            report_content = result.tasks_output[-1].raw\n",
    "        else:\n",
    "            report_content = str(result)\n",
    "        \n",
    "        filename = f\"research_report.md\"\n",
    "        \n",
    "        # Save to file\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            f.write(report_content)\n",
    "        \n",
    "        print(f\"Report successfully saved to: {filename}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error saving report to file: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737a56fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the urban planning crew\n",
    "deep_research_crew = Crew(\n",
    "    # include all the agents\n",
    "    agents=[research_planner, \n",
    "            internet_researcher, \n",
    "            fact_checker, \n",
    "            report_writer],\n",
    "    # include all the tasks in the order to be executed\n",
    "    tasks=[create_research_plan, \n",
    "           gather_research_data, \n",
    "           verify_information_quality, \n",
    "           write_final_report],\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    # add memory to the crew\n",
    "    memory=True,\n",
    "    # add the after kickoff hook\n",
    "    after_kickoff_callbacks=[save_file_hook]\n",
    "\n",
    "    ### END CODE HERE ###\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4aefb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "\n",
    "# write your query in the \"user_query\" value\n",
    "inputs = {\n",
    "    \"user_query\": \"Evaluate the top five emerging AI tools for automating competitive market analysis, including their features, limitations, costs, and ideal use cases for a mid-sized marketing firm.\"\n",
    "}\n",
    "\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad333e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the crew's tasks\n",
    "result = deep_research_crew.kickoff(inputs=inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
