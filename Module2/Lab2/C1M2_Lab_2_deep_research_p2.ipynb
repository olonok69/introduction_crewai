{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2d420ab",
   "metadata": {},
   "source": [
    "# Automatic Deep Research - Adding custom tools\n",
    "\n",
    "Welcome to the second practice lab of this module! \n",
    "\n",
    "In this lab, you will continue working on the deep research crew from Lesson 1. This time you will be writing you own custom tools, and adding them to your agents so that they can give more accurate responses.\n",
    "\n",
    "**What you'll learn:**\n",
    "- How to create custom tools for your agents\n",
    "\n",
    "## Background\n",
    "\n",
    "As a research consultant, you're constantly tasked with producing comprehensive reports on diverse topics for demanding clients. You need to build an AI research crew that can rapidly gather, verify, and synthesize information from across the internet, delivering reliable, fact-checked reports that meet tight deadlines and exacting standards regardless of the subject matter.\n",
    "\n",
    "## General instructions\n",
    "In this lab you will be presented with a structure of the code, but you will need to complete some of it. \n",
    "\n",
    "To successfully run this lab, replace all instances of the placeholder `None` with your own code. Sections where you need to write code will be delimited between `### START CODE HERE ###` and `### END CODE HERE ###`.\n",
    "\n",
    "If you are stuck, or simply want to copy a solution into your notebook so that you can execute it, you can find all solution code inside the [Solution](Solution) folder.\n",
    "\n",
    "**<font color='#5DADEC'>Please make sure to save your work periodically, so you don't lose any progress.</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1624d3",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "\n",
    "- [1. Problem statement](#1)\n",
    "- [2. Set up your notebook](#2)\n",
    "- [3. Tools](#3)\n",
    "- [4. Agents](#4)\n",
    "- [5. Guardrails](#5)\n",
    "- [6. Tasks](#6)\n",
    "- [7. Execution hooks](#7)\n",
    "- [8. Crew](#8)\n",
    "  - [8.1. Define the crew](#8-1)\n",
    "  - [8.2. Define the inputs](#8-2)\n",
    "  - [8.3. Run the crew](#8-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99277450",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "\n",
    "## 1. Problem statement\n",
    "\n",
    "The goal of this lab is to take the multi-agent system that can interpret a user's input, and create an action plan, then do the actual research and fact checking, and finally output a report you can share with the client, and add tools to the agents so they can be better at achieving their goals.\n",
    "\n",
    "You will reuse the code from the first practice lab of this module, so you only need to write new code in the sections [Tools](#3), [Agents](#4), and [Define the inputs](#8.2), the rest of the lab remains the same, with the solution to the previous lab already given to you.\n",
    "\n",
    "Here is a visual summary of the structure of your crew, as well as the new elements you will be adding: \n",
    "\n",
    "<img src=\"../images/lab2-agents-tasks-diagram.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2ec080",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "\n",
    "## 2. Set up your notebook\n",
    "\n",
    "Begin by setting up the notebook by importing all necessary modules, and configuring the environment variables so you can connect to OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fe220a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Agent, Task, Crew, LLM\n",
    "from crewai_tools import EXASearchTool, ScrapeWebsiteTool\n",
    "import os\n",
    "os.environ[\"CREWAI_TESTING\"] = \"true\"\n",
    "from utils import get_openai_api_key, get_exa_api_key\n",
    "from IPython.display import Markdown\n",
    "import yaml\n",
    "\n",
    "# set the OpenAI model (gpt-4o-mini)\n",
    "os.environ[\"MODEL\"] = \"gpt-4o-mini\"\n",
    "# set up the OpenAI API key \n",
    "os.environ[\"OPENAI_API_KEY\"] = get_openai_api_key()\n",
    "# set the exa API key\n",
    "os.environ[\"EXA_API_KEY\"] = get_exa_api_key()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a3d496",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "\n",
    "## 3. Tools\n",
    "\n",
    "The final goal of this Crew you've been building during the course is to provide the user with a complete report containing researched information about a topic, and what is a report without some cool graphics?\n",
    "\n",
    "In the next cell, you will be writing a custom tool that automatically creates charts based on a report of gathered information. This tool will be added to the **Report Writer** agent, so it can add visualization into the final report. \n",
    "\n",
    "Remember that the base structure for a custom tool is\n",
    "```python\n",
    "class MyCustomTool(BaseTool):\n",
    "    name: str = \"Name of my tool\"\n",
    "    description: str = \"What this tool does. It's vital for effective utilization.\"\n",
    "    args_schema: Type[BaseModel] = {}\n",
    "\n",
    "    def _run(self, argument: str) -> str:\n",
    "        # Your tool's logic here\n",
    "        return \"Tool's result\"\n",
    "```\n",
    "\n",
    "In this case, you will need to complete the `CustomPlotTool` class with: \n",
    "- `name`: a suitable name for the tool\n",
    "- `description`: This should be a detailed description of the tool. Mention:\n",
    "    - The expected input: the full validated information, as a string\n",
    "    - What it does: automatically generates plots from text\n",
    "- `_run()` function: specify the type of input and output expected by the tool\n",
    "\n",
    "The code for generating the plots is already given to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc99491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages needed for the custom tool\n",
    "from crewai.tools import BaseTool\n",
    "from crewai import LLM\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "# Define the custom tool for creating plots\n",
    "class CustomPlotTool(BaseTool):\n",
    "    ### START CODE HERE ###\n",
    "    name: None=\"None\"\n",
    "    description: None=\"None\"\n",
    "    def _run(self, research: None) -> str:\n",
    "    ### END CODE HERE ###\n",
    "        try:\n",
    "            extraction_prompt = f\"\"\"\n",
    "            You are an expert data visualization assistant. Analyze the provided research text and identify meaningful, insightful charts that can be created to visualize quantifiable data supporting the research's key insights and findings. Only suggest charts for data that includes numerical values, measurable trends, comparisons, or categorical distributions that can be effectively plotted.\n",
    "\n",
    "            Focus on creating visualizations that highlight trends, comparisons, distributions, or relationships that add value to the research. Avoid suggesting charts for purely qualitative or non-quantifiable information.\n",
    "\n",
    "            For each chart, provide a JSON object with:\n",
    "              - \"chart_type\" (string: choose from \"line\" for trends over time/continuous, \"bar\" for comparisons, \"histogram\" for distributions, \"scatter\" for relationships, \"pie\" for proportions)\n",
    "              - \"x_axis\" (string: variable name for x-axis, e.g., \"year\", \"category\")\n",
    "              - \"y_axis\" (string: variable name for y-axis, e.g., \"value\", \"count\")\n",
    "              - \"color\" (string: optional variable for color grouping/hue, or null if not applicable)\n",
    "              - \"Title\" (string: descriptive, insightful title that explains what the chart shows)\n",
    "              - \"data\" (dictionary: keys matching x_axis, y_axis, and color variables; values as lists of extracted numerical/categorical data from the research)\n",
    "\n",
    "            Ensure data is accurately extracted and formatted as lists. If a variable has multiple series (e.g., for color), include all in the data dictionary.\n",
    "\n",
    "            If no quantifiable data suitable for meaningful visualization is present in the research, return an empty array [].\n",
    "\n",
    "            Text:\n",
    "            {research}\n",
    "\n",
    "            Example output (return valid JSON only):\n",
    "            [\n",
    "              {{\"chart_type\": \"line\", \"x_axis\": \"year\", \"y_axis\": \"funding_amount\", \"color\": \"sector\", \"Title\": \"AI Research Funding Trends by Sector\", \"data\": {{\"year\": [2020, 2021, 2022], \"funding_amount\": [2.5, 3.8, 5.2], \"sector\": [\"Healthcare\", \"Finance\", \"Tech\"]}}}},\n",
    "              {{\"chart_type\": \"bar\", \"x_axis\": \"tool_name\", \"y_axis\": \"adoption_rate\", \"color\": null, \"Title\": \"Market Adoption Rates of AI Tools\", \"data\": {{\"tool_name\": [\"ToolA\", \"ToolB\", \"ToolC\"], \"adoption_rate\": [45, 67, 23]}}}}\n",
    "            ]\n",
    "\n",
    "            Return only the JSON array, no additional text or explanations.\n",
    "            \"\"\"\n",
    "            llm = LLM(model=\"gpt-4o-mini\",)  # Initialize the LLM instance\n",
    "            llm_response = llm.call([{\"role\": \"user\", \"content\": extraction_prompt}])\n",
    "\n",
    "            # Clean the response to extract just the JSON part\n",
    "            llm_response = llm_response.strip()\n",
    "            if llm_response.startswith('```json'):\n",
    "                llm_response = llm_response[7:]  # Remove ```json\n",
    "            if llm_response.endswith('```'):\n",
    "                llm_response = llm_response[:-3]  # Remove ```\n",
    "            llm_response = llm_response.strip()\n",
    "\n",
    "            # --- Step 2: Parse the LLM output ---\n",
    "            charts_data = json.loads(llm_response)\n",
    "\n",
    "            if not isinstance(charts_data, list) or len(charts_data) == 0:\n",
    "                return \"No information found in the research to visualize.\"\n",
    "\n",
    "            plots_created = []\n",
    "\n",
    "            # --- Step 3: Create plots for each chart ---\n",
    "            for i, chart_info in enumerate(charts_data):\n",
    "                try:\n",
    "                    # Extract chart configuration\n",
    "                    chart_type = chart_info.get(\"chart_type\", None).lower()\n",
    "                    x_axis = chart_info.get(\"x_axis\", \"x\")\n",
    "                    y_axis = chart_info.get(\"y_axis\", \"y\") \n",
    "                    title = chart_info.get(\"Title\", f\"Chart {i+1}\")\n",
    "                    hue = chart_info.get(\"color\", None)\n",
    "                    data = chart_info.get(\"data\", {})\n",
    "\n",
    "                    # Create DataFrame from the data\n",
    "                    df = pd.DataFrame(data)\n",
    "\n",
    "                    if df.empty:\n",
    "                        continue\n",
    "\n",
    "                    # Create the plot\n",
    "                    plt.figure(figsize=(10, 6))\n",
    "\n",
    "                    if chart_type == \"line\":\n",
    "                        sns.lineplot(data=df, x=x_axis, y=y_axis, marker=\"o\", hue=hue)\n",
    "                    elif chart_type in [\"bar\", \"column\"]:\n",
    "                        sns.barplot(data=df, x=x_axis, y=y_axis, hue=hue)\n",
    "                    elif chart_type == \"histogram\":\n",
    "                        plt.hist(df[y_axis], bins=10, alpha=0.7, hue=hue)\n",
    "                        plt.xlabel(y_axis)\n",
    "                        plt.ylabel(\"Frequency\")\n",
    "                    elif chart_type == \"scatter\":\n",
    "                        # Default to scatter plot\n",
    "                        sns.scatterplot(data=df, x=x_axis, y=y_axis, hue=hue)\n",
    "                    elif chart_type == \"pie\":\n",
    "                        # For pie chart, assume y_axis is values, x_axis is labels\n",
    "                        plt.pie(df[y_axis], labels=df[x_axis], autopct='%1.1f%%', startangle=90)\n",
    "                        plt.title(title)\n",
    "                        plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "                    plt.title(title)\n",
    "                    plt.xticks(rotation=45)\n",
    "                    plt.tight_layout()\n",
    "\n",
    "                    # --- Step 4: Save the plot ---\n",
    "                    os.makedirs(\"plots\", exist_ok=True)\n",
    "                    filename = f\"plots/plot_{i+1}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png\"\n",
    "                    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "                    plt.close()\n",
    "\n",
    "                    plots_created.append(filename)\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error creating chart {i+1}: {str(e)}\")\n",
    "                    continue\n",
    "\n",
    "            if plots_created:\n",
    "                return f\"Successfully created {len(plots_created)} plots: {', '.join(plots_created)}\"\n",
    "            else:\n",
    "                return \"No plots could be created from the extracted data.\"\n",
    "\n",
    "        except json.JSONDecodeError as e:\n",
    "            return f\"Error parsing LLM response as JSON: {str(e)}\"\n",
    "        except Exception as e:\n",
    "            return f\"Error generating smart plot: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee80e37",
   "metadata": {},
   "source": [
    "As in the previous labs, you will still use the web search and scraping tools for the **Internet Researcher** and **Fact Checker** agents, which you will initialize in the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4218fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tools instances\n",
    "exa_search_tool = EXASearchTool(base_url=os.getenv(\"EXA_BASE_URL\"))\n",
    "scrape_website_tool = ScrapeWebsiteTool()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97578602",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a>\n",
    "\n",
    "## 4. Agents\n",
    "\n",
    "For this system, you will use four agents:\n",
    "- Research Planner\n",
    "- Internet Researcher\n",
    "- Fact checker\n",
    "- Report Writer\n",
    "\n",
    "All their arguments (`role`, `goal`, `backstory`) are already given to you in a YAML file, which you will use to configure the agents. If you want to take a closer look go to the [config/agents.yaml](config/agents.yaml) file on the file navigator on the left.\n",
    "\n",
    "In the labs, we have added two parameters not shown in the demo videos: `max_rpm`, and `max_iter`. `max_rpm` sets the maximum requests per minute to avoid rate limits, while `max_iter` limits the maximum iterations before the agent must provide its best answer. Setting these two parameters helps make the agents run a little faster, so the lab doesn't take as long to complete. \n",
    "\n",
    "Don't forget to add the new custom tool to the **Report Writer** agent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704540c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the configuration file for the agents\n",
    "with open('config/agents.yaml', 'r') as file:\n",
    "        agent_config = yaml.safe_load(file)\n",
    "\n",
    "\n",
    "# create the agents using the configuration\n",
    "research_planner = Agent(\n",
    "        config=agent_config['research_planner'],\n",
    "        verbose=True,\n",
    "        max_rpm=150,\n",
    "        max_iter=15\n",
    "        )\n",
    "\n",
    "internet_researcher = Agent( \n",
    "        config=agent_config['internet_researcher'],\n",
    "        verbose=True,\n",
    "        tools=[exa_search_tool, scrape_website_tool],\n",
    "        max_rpm=150,\n",
    "        max_iter=15\n",
    "        )\n",
    "\n",
    "fact_checker = Agent(\n",
    "        config=agent_config['fact_checker'],\n",
    "        verbose=True,\n",
    "        tools=[exa_search_tool, scrape_website_tool],\n",
    "        max_rpm=150,\n",
    "        max_iter=15\n",
    "        )\n",
    "\n",
    "report_writer = Agent(\n",
    "        config=agent_config['report_writer'],\n",
    "        verbose=True,\n",
    "        ### START CODE HERE ### \n",
    "        # add the automatic plot tool\n",
    "        tools=[None()],\n",
    "        ### END CODE HERE ###\n",
    "        max_rpm=150,\n",
    "        max_iter=15\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5669aee7",
   "metadata": {},
   "source": [
    "<a id=\"5\"></a>\n",
    "\n",
    "## 5. Guardrails\n",
    "\n",
    "To make your system more robust, you want to add guardrails to your tasks. These guardrails provide a way to validate and transform task outputs before they are passed to the next task, helping ensure data quality and providing feedback to agents when their output doesn't meet specific criteria. You can find out more about guardrails in the [docs](https://docs.crewai.com/en/concepts/tasks#task-guardrails).\n",
    "\n",
    "\n",
    "In particular, you will implement a guardrail for the final output. You want to make sure the final report has all the sections needed: \n",
    "- Summary\n",
    "- Insights (or recommendations)\n",
    "- Citations (or References)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239299d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# write the custom guardrail function\n",
    "def write_report_guardrail(output):\n",
    "    # get the raw output from the TaskOutput object\n",
    "    try:\n",
    "        output = output if type(output)==str else output.raw \n",
    "    except Exception as e:\n",
    "        return (False, (\"Error retrieving the `raw` argument: \"\n",
    "                        f\"\\n{str(e)}\\n\"\n",
    "                        )\n",
    "                )\n",
    "    \n",
    "    # convert the output to lowercase\n",
    "    output_lower = output.lower()\n",
    "\n",
    "    # check that the summary section exists\n",
    "    if not re.search(r'#+.*summary', output_lower):\n",
    "        return (False, \n",
    "                \"The report must include a Summary section with a header like '## Summary'\"\n",
    "                )\n",
    "\n",
    "    # check that the insights or recommendations sections exist\n",
    "    if not re.search(r'#+.*insights|#+.*recommendations', output_lower):\n",
    "        return (False, \n",
    "                \"The report must include an Insights section with a header like '## Insights'\"\n",
    "                )\n",
    "\n",
    "    # check that the citations (or references) section exists\n",
    "    if not re.search(r'#+.*citations|#+.*references', output_lower): \n",
    "        return (False, \n",
    "                \"The report must include a Citations (or References) section with a header like '## Citations'\"\n",
    "                )\n",
    "    return (True, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f4f39a",
   "metadata": {},
   "source": [
    "<a id=\"6\"></a>\n",
    "\n",
    "## 6. Tasks\n",
    "Now you are ready to create the tasks. Just as you did with the agents, you will load the configuration from a YAML file, which you can find in [`config/tasks.yaml`](config/tasks.yaml).  \n",
    "\n",
    "In order to actually add the charts to the final report you will need to update the `write_final_report` task in the [`tasks.yaml`](config/tasks.yaml) file. Adapt the `description` and `expected_output` to include instructions include the charts generated by the custom tool.\n",
    "\n",
    "Once that's done, run the next cell to create each task. The agents, guardrails, and context are already defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5e46c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the configuration file for the tasks\n",
    "with open('config/tasks.yaml', 'r') as file:\n",
    "    task_config = yaml.safe_load(file)\n",
    "\n",
    "\n",
    "# create the tasks using the configuration\n",
    "create_research_plan = Task( \n",
    "    config=task_config['create_research_plan'],\n",
    "    agent=research_planner \n",
    ")\n",
    "\n",
    "gather_research_data = Task(\n",
    "    config=task_config['gather_research_data'],\n",
    "    agent=internet_researcher,\n",
    ")\n",
    "\n",
    "verify_information_quality = Task(\n",
    "    config=task_config['verify_information_quality'],\n",
    "    agent=fact_checker, \n",
    ")\n",
    "\n",
    "write_final_report = Task( \n",
    "    config=task_config['write_final_report'],\n",
    "    agent=report_writer, \n",
    "    guardrails=[write_report_guardrail],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b01895",
   "metadata": {},
   "source": [
    "<a id=\"7\"></a>\n",
    "\n",
    "## 7. Execution hooks\n",
    "\n",
    "The last step before creating the Crew is creating an [after kickoff hook](https://docs.crewai.com/en/learn/before-and-after-kickoff-hooks#after-kickoff-hook). \n",
    "\n",
    "In this case, you will create a hook that takes the final output and saves it to a Markdown file on your local file system. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f065a43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_file_hook(result):\n",
    "    \"\"\"\n",
    "    Save the final research report to a local markdown file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get the final report content from the last task output\n",
    "        if hasattr(result, 'tasks_output') and result.tasks_output:\n",
    "            report_content = result.tasks_output[-1].raw\n",
    "        else:\n",
    "            report_content = str(result)\n",
    "        \n",
    "        filename = f\"research_report-p2.md\"\n",
    "        \n",
    "        # Save to file\n",
    "        with open(filename, 'w', encoding='utf-8') as f:\n",
    "            f.write(report_content)\n",
    "        \n",
    "        print(f\"Report successfully saved to: {filename}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error saving report to file: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6ce21b",
   "metadata": {},
   "source": [
    "<a id=\"8\"></a>\n",
    "\n",
    "## 8. Crew\n",
    "\n",
    "<a id=\"8-1\"></a>\n",
    "\n",
    "### 8.1. Define the crew\n",
    "Run the next cell to define the crew. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737a56fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the urban planning crew\n",
    "deep_research_crew = Crew(\n",
    "    # include all the agents\n",
    "    agents=[research_planner, \n",
    "            internet_researcher, \n",
    "            fact_checker, \n",
    "            report_writer],\n",
    "    # include all the tasks in the order to be executed\n",
    "    tasks=[create_research_plan, \n",
    "           gather_research_data, \n",
    "           verify_information_quality, \n",
    "           write_final_report],\n",
    "    # add memory to the crew\n",
    "    memory=True,\n",
    "    # add the after kickoff hook\n",
    "    after_kickoff_callbacks=[save_file_hook]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8490dfb3",
   "metadata": {},
   "source": [
    "<a id=\"8-2\"></a>\n",
    "\n",
    "### 8.2. Define the inputs\n",
    "\n",
    "Use the next cell to define the inputs to your Crew. This should represent the user's query. Try using the same query as in the previous lab, so you can compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4aefb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ###\n",
    "\n",
    "# write your query in the \"user_query\" value\n",
    "inputs = { \n",
    "        \"user_query\": None\n",
    "}\n",
    "### END CODE HERE ###   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d31b0b",
   "metadata": {},
   "source": [
    "<a id=\"8-3\"></a>\n",
    "\n",
    "### 8.3. Run the crew\n",
    "Now you can run, or kick off, the crew to get the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad333e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the crew's tasks\n",
    "result = deep_research_crew.kickoff(inputs=inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57542808",
   "metadata": {},
   "source": [
    "After it finishes running, you should be able to see the newly created Markdown file with your report in the file navigator on the left. You can compare it with the results from the first lab, can you see any differences?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81cea0c",
   "metadata": {},
   "source": [
    "Congratulations! You've successfully completed this lab ðŸŽ‰"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
